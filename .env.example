# Application Environment
ENVIRONMENT=development
DEBUG=False
HOST=0.0.0.0
PORT=8000

# Security
SECRET_KEY="your-secret-key"
ALLOWED_HOSTS=*
CORS_ORIGINS=*

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Feature Flags
ENABLE_AUDIO_UPLOAD=True
ENABLE_URL_PROCESSING=True
ENABLE_TRANSLATION=True
ENABLE_SUMMARIZATION=True
# Set to False for synchronous processing (useful for testing and development)
# Set to True for asynchronous processing via Celery workers (production)
ENABLE_ASYNC_PROCESSING=False

# Rate Limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=3600

# File Processing
MAX_FILE_SIZE=104857600
SUPPORTED_FORMATS=mp3,wav,flac,ogg
TEMP_DIR="/tmp/audio-processor"

# Database Configuration
DATABASE_URL="postgresql+asyncpg://user:password@localhost:5432/dbname"
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=30
DB_POOL_TIMEOUT=30
DB_POOL_RECYCLE=3600
DB_ECHO_SQL=False

# Redis Cache Configuration
REDIS_URL="redis://localhost:6379/0"
REDIS_CONNECT_TIMEOUT=10
REDIS_SOCKET_TIMEOUT=10
REDIS_MAX_CONNECTIONS=50

# Keycloak OAuth2 Authentication Configuration
KEYCLOAK_URL="http://localhost:8080"
KEYCLOAK_REALM="master"
KEYCLOAK_CLIENT_ID="your-client-id"
KEYCLOAK_CLIENT_SECRET="your-client-secret"
JWT_ALGORITHM="RS256"
JWT_VERIFY_SIGNATURE=True
JWT_VERIFY_AUDIENCE=True

# WhisperX Model Configuration
WHISPERX_MODEL_SIZE="base"
WHISPERX_DEVICE="cuda"
WHISPERX_COMPUTE_TYPE="float16"
WHISPERX_LANGUAGE="auto"
WHISPERX_BATCH_SIZE=8
WHISPERX_CHAR_ALIGNMENTS=False
WHISPERX_VAD_ONSET=0.5
WHISPERX_VAD_OFFSET=0.363

# Speaker Diarization Configuration
DIARIZATION_MODEL="pyannote/speaker-diarization"
DIARIZATION_DEVICE="cuda"
HUGGINGFACE_TOKEN=""
DIARIZATION_MIN_SPEAKERS=2
DIARIZATION_MAX_SPEAKERS=10
DIARIZATION_ENABLED=true

# Celery Background Task Configuration
CELERY_BROKER_URL="redis://localhost:6379/1"
CELERY_RESULT_BACKEND="redis://localhost:6379/2"
CELERY_TASK_SERIALIZER="json"
CELERY_RESULT_SERIALIZER="json"
CELERY_ACCEPT_CONTENT=["json"]
CELERY_TIMEZONE="UTC"
CELERY_ENABLE_UTC=True
CELERY_WORKER_CONCURRENCY=4

# Summarization Service Configuration
SUMMARIZATION_API_URL="http://localhost:8001/summarize"
SUMMARIZATION_API_KEY="" # Optional: API key for summarization service
SUMMARIZATION_MODEL="meta-llama/llama-4-maverick"

# Translation Service Configuration
TRANSLATION_ENABLED=False
TRANSLATION_PROVIDER="huggingface"
TRANSLATION_MODEL_NAME="Helsinki-NLP/opus-mt-en-es"
TRANSLATION_DEVICE="cpu"

# Graph Database Configuration
GRAPH_ENABLED=True
GRAPH_DATABASE_TYPE="neo4j"
GRAPH_DATABASE_URL="bolt://localhost:7687"
GRAPH_DATABASE_USERNAME="neo4j"
GRAPH_DATABASE_PASSWORD="devpassword"
GRAPH_DATABASE_NAME="neo4j"
GRAPH_DATABASE_MAX_CONNECTION_LIFETIME=1800
GRAPH_DATABASE_MAX_CONNECTION_POOL_SIZE=50
GRAPH_DATABASE_CONNECTION_ACQUISITION_TIMEOUT=30

# Graph Processing Configuration
GRAPH_PROCESSING_BATCH_SIZE=100
GRAPH_PROCESSING_EXTRACTION_QUEUE="graph_extraction"

# Graph Topic Extraction Configuration
GRAPH_TOPIC_EXTRACTION_METHOD="keyword_matching"

# Graph Entity Extraction Configuration
GRAPH_ENTITY_EXTRACTION_METHOD="llm_based"

# Graph Sentiment Analysis Configuration
GRAPH_SENTIMENT_ANALYSIS_ENABLED=True
GRAPH_SENTIMENT_ANALYSIS_METHOD="llm_based"

# Graph Relationship Extraction Configuration
GRAPH_RELATIONSHIP_EXTRACTION_METHOD="llm_based"

# LLM Configuration for Graph Processing
GRAPH_LLM_PROVIDER="openrouter"
GRAPH_LLM_MODEL="meta-llama/llama-4-maverick-17b-128e-instruct"
GRAPH_LLM_API_KEY=""
GRAPH_LLM_API_BASE=""
GRAPH_LLM_MAX_TOKENS=1000
GRAPH_LLM_TEMPERATURE=0.1
GRAPH_LLM_BATCH_SIZE=5

# LLM Provider API Keys (choose based on GRAPH_LLM_PROVIDER)
OPENAI_API_KEY=""
ANTHROPIC_API_KEY=""
OPENROUTER_API_KEY="sk-or-v1-"

# Examples for different LLM providers:
# For OpenAI:
#   GRAPH_LLM_PROVIDER=openai
#   GRAPH_LLM_MODEL=gpt4o-mini
#   OPENAI_API_KEY=sk-...
#
# For Anthropic:
#   GRAPH_LLM_PROVIDER=anthropic
#   GRAPH_LLM_MODEL=claude-3-haiku-20240307
#   ANTHROPIC_API_KEY=sk-ant-...
#
# For OpenRouter:
#   GRAPH_LLM_PROVIDER=openrouter
#   GRAPH_LLM_MODEL=meta-llama/llama-4-maverick-17b-128e-instruct
#   OPENROUTER_API_KEY=sk-or-v1-...
#
# For Local LLM:
#   GRAPH_LLM_PROVIDER=local
#   GRAPH_LLM_MODEL=llama4-maverick-17b-128e-instruct
#   GRAPH_LLM_API_BASE=http://localhost:11434
