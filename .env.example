# Application Environment
ENVIRONMENT=development
DEBUG=False
HOST=0.0.0.0
PORT=8000

# Security
SECRET_KEY="your-secret-key"
ALLOWED_HOSTS=*
CORS_ORIGINS=*

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Feature Flags
ENABLE_AUDIO_UPLOAD=True
ENABLE_URL_PROCESSING=True
ENABLE_TRANSLATION=True
ENABLE_SUMMARIZATION=True

# Rate Limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=3600

# File Processing
MAX_FILE_SIZE=104857600  # 100 MB
SUPPORTED_FORMATS=mp3,wav,flac,ogg
TEMP_DIR="/tmp/audio-processor"

# Database Configuration
DATABASE_URL="postgresql+asyncpg://user:password@localhost:5432/dbname"
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=30
DB_POOL_TIMEOUT=30
DB_POOL_RECYCLE=3600
DB_ECHO_SQL=False

# Redis Cache Configuration
REDIS_URL="redis://localhost:6379/0"
REDIS_CONNECT_TIMEOUT=10
REDIS_SOCKET_TIMEOUT=10
REDIS_MAX_CONNECTIONS=50

# Keycloak OAuth2 Authentication Configuration
KEYCLOAK_URL="http://localhost:8080"
KEYCLOAK_REALM="master"
KEYCLOAK_CLIENT_ID="your-client-id"
KEYCLOAK_CLIENT_SECRET="your-client-secret"
JWT_ALGORITHM="RS256"
JWT_VERIFY_SIGNATURE=True
JWT_VERIFY_AUDIENCE=True

# WhisperX Model Configuration
WHISPERX_MODEL_SIZE="base"
WHISPERX_DEVICE="cuda"
WHISPERX_COMPUTE_TYPE="float16"
WHISPERX_LANGUAGE="auto"
WHISPERX_BATCH_SIZE=8
WHISPERX_CHAR_ALIGNMENTS=False
WHISPERX_VAD_ONSET=0.5
WHISPERX_VAD_OFFSET=0.363

# Speaker Diarization Configuration
DIARIZATION_MODEL="pyannote/speaker-diarization"
DIARIZATION_DEVICE="cuda"
HUGGINGFACE_TOKEN="" # Optional: Your Hugging Face token for private models
DIARIZATION_MIN_SPEAKERS="" # Optional: Minimum number of speakers
DIARIZATION_MAX_SPEAKERS="" # Optional: Maximum number of speakers

# Celery Background Task Configuration
CELERY_BROKER_URL="redis://localhost:6379/1"
CELERY_RESULT_BACKEND="redis://localhost:6379/2"
CELERY_TASK_SERIALIZER=json
CELERY_RESULT_SERIALIZER=json
CELERY_ACCEPT_CONTENT=json
CELERY_TIMEZONE=UTC
CELERY_ENABLE_UTC=True
CELERY_WORKER_CONCURRENCY=4

# Summarization Service Configuration
SUMMARIZATION_API_URL="http://localhost:8001/summarize"
SUMMARIZATION_API_KEY="" # Optional: API key for summarization service
SUMMARIZATION_MODEL="gpt-3.5-turbo"

# Translation Service Configuration
TRANSLATION_ENABLED=False
TRANSLATION_PROVIDER="huggingface"
TRANSLATION_MODEL_NAME="Helsinki-NLP/opus-mt-en-es"
TRANSLATION_DEVICE="cpu"

# Graph Database Configuration
GRAPH_ENABLED=False
GRAPH_DATABASE_TYPE="neo4j"
GRAPH_DATABASE_URL="bolt://localhost:7687"
GRAPH_DATABASE_USERNAME="neo4j"
GRAPH_DATABASE_PASSWORD="password"
GRAPH_DATABASE_NAME="neo4j"
GRAPH_DATABASE_MAX_CONNECTION_LIFETIME=1800
GRAPH_DATABASE_MAX_CONNECTION_POOL_SIZE=50
GRAPH_DATABASE_CONNECTION_ACQUISITION_TIMEOUT=30

# Graph Processing Configuration
GRAPH_PROCESSING_BATCH_SIZE=100
GRAPH_PROCESSING_EXTRACTION_QUEUE="graph_extraction"

# Graph Topic Extraction Configuration
GRAPH_TOPIC_EXTRACTION_METHOD="keyword_matching"  # Options: keyword_matching, llm_based, hybrid
GRAPH_TOPIC_KEYWORDS="{}"  # JSON object with topic keywords

# Graph Entity Extraction Configuration
GRAPH_ENTITY_EXTRACTION_METHOD="regex_patterns"  # Options: regex_patterns, llm_based, hybrid
GRAPH_ENTITY_EXTRACTION_PATTERNS="{}"  # JSON object with entity patterns

# Graph Sentiment Analysis Configuration
GRAPH_SENTIMENT_ANALYSIS_ENABLED=False
GRAPH_SENTIMENT_ANALYSIS_METHOD="llm_based"  # Options: llm_based, ml_model

# Graph Relationship Extraction Configuration
GRAPH_RELATIONSHIP_EXTRACTION_METHOD="rule_based"  # Options: rule_based, llm_based, hybrid

# LLM Configuration for Graph Processing
GRAPH_LLM_PROVIDER="meta-llama"  # Options: openai, anthropic, openrouter, local
GRAPH_LLM_MODEL="meta-llama/llama-4-maverick"
GRAPH_LLM_API_KEY=""  # Optional: Direct API key (prefer provider-specific env vars)
GRAPH_LLM_API_BASE=""  # Optional: Custom API base URL
GRAPH_LLM_MAX_TOKENS=1000
GRAPH_LLM_TEMPERATURE=0.1
GRAPH_LLM_BATCH_SIZE=5

# LLM Provider API Keys (choose based on GRAPH_LLM_PROVIDER)
OPENAI_API_KEY=""  # For OpenAI provider
ANTHROPIC_API_KEY=""  # For Anthropic provider
OPENROUTER_API_KEY="sk-or-v1-"  # For OpenRouter provider

# Examples for different LLM providers:
# For OpenAI:
#   GRAPH_LLM_PROVIDER=openai
#   GRAPH_LLM_MODEL=gpt4o-mini
#   OPENAI_API_KEY=sk-...
#
# For Anthropic:
#   GRAPH_LLM_PROVIDER=anthropic
#   GRAPH_LLM_MODEL=claude-3-haiku-20240307
#   ANTHROPIC_API_KEY=sk-ant-...
#
# For OpenRouter:
#   GRAPH_LLM_PROVIDER=openrouter
#   GRAPH_LLM_MODEL=meta-llama/llama-4-maverick
#   OPENROUTER_API_KEY=sk-or-v1-...
#
# For Local LLM:
#   GRAPH_LLM_PROVIDER=local
#   GRAPH_LLM_MODEL=llama4-maverick-17b-128e-instruct
#   GRAPH_LLM_API_BASE=http://localhost:11434
